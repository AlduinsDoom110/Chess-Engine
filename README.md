codex/improve-chess-engine-functionality-in-python
# Chess Engine
This project provides a minimal chess engine implemented in Python. It supports
basic move generation and a minimax search with alpha-beta pruning.
The evaluation function combines piece-square tables with mobility scoring and
simple king-safety heuristics.

## Requirements

* Python 3.8+

## Usage

Run the `main.py` script to play against the engine. Moves are entered in simple
coordinate notation, for example `e2e4`.

```bash
python3 main.py --book mybook.bin
```

## Modules

- `board.py` implements the board representation and move generation.
- `engine.py` contains evaluation and search functions including mobility and
  king-safety scoring.
- `main.py` provides a very small command line interface.

The code is intended as a starting point for further experiments and
improvements.

### Recent additions

* Bitboard utility module with fast ``int.bit_count()`` popcount.
* Precomputed pawn move and capture tables.
* Simple sliding attack generators.
* Zobrist hash updated after every move.
* Default search depth is 5 plies but can be changed via the UCI `go depth`
  command or the `--depth` option when running `main.py`.
* ``perft`` validation routines relying on ``python-chess``.
* Rotated bitboards with caching for rook and bishop rays.
* Pseudo-legal move generation with lazy legality checks.
* Basic attack map cache keyed by occupancy.
* Opening book support via Polyglot ``.bin`` files. Use ``--book <path>`` or
  ``setoption name Book value <file>`` to enable.

This repository contains a small Python chess engine built on top of the
[`python-chess`](https://python-chess.readthedocs.io/) library.  It supports all
conventional chess rules and uses a simple minimax search with alpha‑beta
pruning as a demonstration engine.

## Requirements

* Python 3.8+
* `python-chess` (`pip install chess`)

## Usage

Run the command line interface and play against the engine:

```bash
python3 main.py
```

Enter moves in coordinate notation such as `e2e4` or, for promotions,
`e7e8q`.

### Using the engine with UCI

The repository also includes a minimal [UCI](https://en.wikipedia.org/wiki/Universal_Chess_Interface)
driver.  Run `uci.py` and connect to it from any UCI compatible GUI:

```bash
python3 uci.py
```

Only a subset of the protocol is supported (e.g. `position` and `go depth N`).
Use `setoption name Book value <file>` to load a Polyglot book when running
under UCI.

### Threading and Multi-PV

`uci.py` now supports the standard `Threads` and `MultiPV` options.  When more
than one thread is requested the engine runs a *Lazy SMP* style search: each
worker performs its own iterative deepening search while sharing a single
transposition table through Python's multiprocessing utilities.  This allows the
full search algorithm (including move ordering and iterative deepening) to take
advantage of multiple CPU cores.  Use the UCI `setoption` command to control how
many worker processes are spawned and how many principal variations are
reported:

```text
setoption name Threads value 4
setoption name MultiPV value 3
```

The `go` command will then return the best move as usual while also printing
additional `info multipv` lines for the requested number of variations.

### Running perft

The `perft.py` module provides a simple perft implementation using
`python-chess`. It can be used to validate the engine's move generator:

```bash
python3 -c "import perft, board; print(perft.perft(board.Board(), 3))"
```
Improving Move Generation, Evaluation, and Search in the Chess Engine
1. Move Generation Efficiency
The engine currently generates moves using the python-chess library’s pseudo-legal move generator
GitHub
. This works but incurs Python object overhead and may not fully leverage efficient bit-level operations. To improve move generation performance (a critical bottleneck in search), consider the following optimizations:
Adopt a Bitboard Representation: Represent the board with 64-bit bitboards for each piece type and color. This allows using fast bit operations (shifts, masks, etc.) to generate moves in bulk. For example, pawn moves can be generated by shifting pawn bitboards and masking by empty squares, as the engine partially does with precomputed pawn move bitboards
GitHub
. Bitboards let you compute multiple moves with a single operation (e.g. a bit shift yields all pawn advances one rank) instead of iterating square by square. This can drastically speed up move generation, since Python integer bit ops are implemented in C and are very fast for 64-bit masks.
Use Precomputed Attack Tables / Magic Bitboards for Sliders: For sliding pieces (bishops, rooks, queens), precompute attack bitboards to avoid calculating moves from scratch each time. The engine already uses a rotated bitboard technique with cached attack masks for rooks and bishops
GitHub
GitHub
 – it masks occupancy by rank/file/diagonal and looks up attacks in tables. An even more efficient approach is magic bitboards, which use precomputed bit masks and magic multipliers to directly index an attack table for any occupancy configuration. Magic bitboards yield constant-time move generation for sliders by using the bitboard of blockers as a key to a table of attacks, a method used in Stockfish and other strong engines. Transitioning from rotated bitboards to magic bitboards (or otherwise optimizing the attack cache lookups) could reduce move computation latency. The key idea is to do one array lookup per sliding move instead of iterating along rays or checking occupancy multiple times
GitHub
.
Generate Moves via Bit Operations and Enumerate Bits: With bitboards, you can generate all target squares of a piece in one go (as a bitboard of possible destinations). Then, iterate through the set bits (using bit scan or bit count operations) to enumerate moves. This avoids creating chess.Move objects for every pseudo-legal move. The engine’s bitboard utility already provides a fast popcount function for counting bits
GitHub
, and Python’s int.bit_count() can be used as well. By using bitboards and bit-scans, the engine can represent moves compactly (e.g. as from-square and to-square indices or a 16-bit packed move code
GitHub
) rather than heavy Python objects, greatly reducing overhead in the move generator. In fact, the engine already packs moves into an integer for transposition table storage
GitHub
; using a similar compact move representation during move generation and search would improve speed and memory usage.
Efficient Legal Move Filtering (Pins & Checks): Generating only legal moves (as opposed to all pseudo-legal moves) can save time by not exploring illegal branches. Strong engines often identify pinned pieces and restrict their moves during generation. You can use bitboards to detect pins: for each sliding enemy piece (rook, bishop, queen) aligned with your king, compute the ray between that piece and the king – any friendly piece on that ray is pinned. When generating moves for a pinned piece, restrict its target squares to those along the pin line (and for the king, exclude moves moving into check by using a precomputed attack map of enemy pieces). This avoids having to “try and unmake” illegal moves. Although the current design uses lazy legality (it generates pseudo-legal moves and checks legality on push
GitHub
), incorporating pin-based move filtering could cut down on illegal move generation, especially in tactics-heavy positions where many moves are not actually legal.
Move Ordering at Generation: Another efficiency angle is to generate moves in a favorable order to reduce sorting overhead later. For instance, you could generate capture moves and quiet moves separately. Captures might be generated first or placed in a separate list so that the search can examine forcing moves early (or exclusively in quiescence search). The engine’s search already sorts moves by heuristics (e.g. history, SEE, etc.)
GitHub
GitHub
, but initially producing moves in approximate good order (e.g. all captures, or using Most-Valuable-Victim/Least-Valuable-Attacker ordering for captures) can complement those heuristics. This way, the most promising moves are considered first without an expensive full sort. Given that the engine uses Python, a full sort on dozens of moves is not too costly, but any reduction in work helps at scale.
In summary, migrating to a bitboard-centric move generator can significantly improve speed. By leveraging bitboard operations (including magic bitboards for sliding attacks) and filtering out illegal moves (pins, etc.) early, the engine will generate legal moves more efficiently. These techniques are standard in fast engines like Stockfish, which represent game state in bitboards and use precomputed attack masks to enumerate moves with minimal looping.
2. Evaluation Heuristics
A chess engine’s evaluation function should accurately assess board positions using domain-specific heuristics. The current engine already implements several classic evaluation features – it uses piece-square tables, mobility counts, king safety bonuses, pawn structure penalties, etc., as noted in the code
GitHub
GitHub
. To further align with strong traditional engines (excluding any neural network eval like NNUE), the following improvements and additions are recommended:
Piece Values and Piece-Square Tables (PST): Continue using and refining PSTs to encode positional value of pieces. The engine uses midgame PST values (from Sunfish) and an endgame king table
GitHub
GitHub
, blended according to game phase
GitHub
. This is a good approach – piece-square tables give pieces incentives to occupy strong squares (e.g. knights in the center, pawns advancing to 5th rank, kings toward corners in endgame). Improvements can include tuning these PST values to better reflect modern engine heuristics or using more granular phase interpolation (e.g. separate opening, midgame, endgame tables). For instance, knights could get extra bonuses for outpost squares and penalties for being on the board edge (which PST already covers somewhat), and bishops might have entries encouraging long diagonals. Ensuring the PSTs are well-calibrated (perhaps via automated tuning or references to grandmaster games) can boost evaluation accuracy. Additionally, the material values (Kaufman values in use
GitHub
) could be tuned to account for imbalances – e.g. the engine might have a slight preference for bishop pair or an exchange (Rook vs minor+pawn) based on these values. Fine-tuning piece values and PSTs using self-play data or known heuristics will make the evaluation more precise.
Mobility and Activity: Rewarding piece mobility – the number of moves or attacks a piece has – is a hallmark of strong evaluations. The engine already computes a mobility score by counting each piece’s attackable squares (using bitboard attack masks and popcount) and weighting them
GitHub
. This should be continued and perhaps refined: ensure that only legal moves are counted (e.g. a bishop pinned to the king shouldn’t contribute full mobility since it can’t actually move freely). The current implementation multiplies mobility by a factor that increases when the piece is nearer the enemy king (proximal bonus)
GitHub
, which is a clever way to value attacks that pressure the king more. Such “tropism” bonuses (distance of piece to enemy king)
GitHub
 are indeed used in engines like Crafty. Weights for mobility can be adjusted per piece type – e.g. knights and bishops typically get higher mobility rewards per square than rooks/queens in many evals, because a minor piece with no moves is usually in a bad spot. The engine’s MOBILITY_WEIGHTS reflects this idea (knights/bishops 4, rooks 2, etc.)
GitHub
. You might consider dynamic mobility scoring: for instance, in closed positions mobility might count a bit less, whereas in open positions it counts more – but since open/closed is roughly correlated with total moves available, the current approach inherently handles that. Overall, continuing to emphasize mobility (perhaps adding a small penalty for very low-mobility pieces to detect trapped pieces) will guide the engine toward active piece play.
King Safety: This is crucial in evaluation – even a material advantage can be negated by a vulnerable king. The engine includes several king safety heuristics: a pawn shield bonus (rewarding pawns directly in front of the king)
GitHub
, a penalty for an “exposed” king if the shield is missing pawns
GitHub
, and an “attacker score” counting enemy pieces attacking squares near the king
GitHub
. To strengthen king safety evaluation, we can expand on these:
Pawn Shield & Open Files: Ensure there’s a penalty for open or semi-open files leading to the king. If the king’s file (or adjacent files) has no friendly pawns, that should be flagged as a weakness. The engine has an OPEN_FILE_PENALTY constant
GitHub
 – implementing a penalty using it (e.g. if no pawn shields the king along a file and an enemy rook/queen is present on that file) would capture this idea. Castled positions usually have 2-3 pawns in front; if those are absent or moved, the king is drafty. The current PAWN_SHIELD_BONUS (30 per pawn in shield) and EXPOSED_KING_PENALTY (30 per missing pawn up to 3)
GitHub
 serve this purpose; we should verify those apply properly and adjust if needed (e.g. perhaps a sliding scale where missing one pawn is a smaller penalty but missing all three is very large).
Attacks on King: Incorporate a more nuanced scoring of enemy attacks near the king. Rather than counting all attackers equally
GitHub
, weigh them by piece: e.g. an enemy queen or rook attacking a square near our king is more dangerous than a knight at the same distance. Strong engines assign “attack units” based on piece type and how many squares near the king are controlled. We could implement a system where each square in the king’s “danger zone” (often defined as the king’s square and all adjacent squares) controlled by an enemy piece contributes points to an enemy attack score, with multipliers for piece type (queen attacks might be 3 units, rook 2, minor 1, etc.). The engine’s existing logic iterates over the king’s adjacent squares and counts enemy attackers
GitHub
; this can be extended by giving, say, +X points for each attacker of type Y. Additionally, multiple pieces attacking the same square could add more (since that square is very dangerous). By increasing the penalty for heavy piece concentration around the king, the engine will prefer safer king positions.
King Placement and Castling: The engine rightly gives a bonus for having castled (50 points when king is on g1/c1 or g8/c8)
GitHub
. We should maintain this, as castling usually improves king safety and connects rooks. Conversely, we might penalize an uncastled king stuck in the center after a certain number of moves. For example, if after 15 moves the king is still on its original square (e1/e8) and has lost castling rights, it could incur a small penalty for being potentially vulnerable. This encourages timely castling. In endgames, the king safety terms should be phased out (which is already handled by blending to an endgame eval where king activity is more important than king safety). Indeed, the engine’s phase interpolation will naturally reduce the effect of pawn shield and attacker penalties as material (phase) decreases
GitHub
.
Pawn Structure: Pawns shape the long-term strategic landscape, so their structure must be evaluated deeply. The engine implements classic pawn structure heuristics – it penalizes doubled pawns (multiple pawns on the same file)
GitHub
, isolated pawns (no friendly pawns on adjacent files)
GitHub
, and backward pawns (pawns that are behind their neighbors and cannot advance without becoming vulnerable)
GitHub
. It also gives a bonus for passed pawns (no enemy pawns ahead on adjacent files)
GitHub
GitHub
. These are all good; some ways to enhance them:
Pawn Islands: Penalize having multiple separate pawn islands. An island is a group of pawns separated by one or more empty files from other pawns. The engine’s isolated pawn penalty partly covers this (each isolated pawn implies an extra island), but you could explicitly count pawn islands for each side and subtract a small penalty (e.g. -5 or -10 per island beyond the first). Fewer pawn islands (ideally one continuous chain of pawns) is generally better for endgames.
Connected Pawns and Chains: Reward pawns that are connected or supporting each other. While the absence of a connection is penalized as isolation/backward, we can positively reward structures like pawn chains (where a pawn is protected by another pawn on a diagonal behind it). This could be a small bonus for each pawn that has a friendly pawn on an adjacent file one rank behind (meaning it’s part of a chain). Such pawns are more resilient and control important squares.
Advanced Passed Pawns: Already giving a base bonus for a passed pawn is good; consider increasing the bonus as the pawn advances to more dangerous ranks. For example, a passed pawn on the 6th or 7th rank could be worth significantly more (since it forces the opponent to allocate resources to stop it). Some engines use a table of passed pawn bonuses by rank. The engine could also check if the passed pawn is supported by a friendly pawn or king, and boost it further if so (a protected passed pawn is extremely strong).
Pawn Tempo and Center Control: Encourage occupying the center with pawns (e.g. a pawn on d4/e4 for White is usually good). This can be partially reflected in PST values for pawns (which likely already give some bonus for central pawns
GitHub
), but an explicit “center control” term could count pawns (and perhaps pieces) in the center and give a few points. The provided SPACE_PAWN_BONUS (6 points per advanced pawn beyond 4th rank) is effectively rewarding space gained by pawns
GitHub
GitHub
, which correlates with center control and territory. This is a sound concept – more advanced pawns = more space. The engine also gives a pawn storm bonus when those advanced pawns are on files near the enemy king
GitHub
, which is great for king attacks. Ensuring these space and pawn-storm bonuses are tuned well (and maybe scaled by phase, so they matter more in middlegame than endgame) will improve strategic understanding.
Piece-Specific Positional Heuristics: Add or enhance heuristics for specific pieces to mimic expert knowledge:
Outposts: Identify outpost squares for knights (and sometimes bishops) – typically a knight on the 5th/6th rank (for White; 3rd/4th for Black) that is protected by a pawn and cannot be attacked by an enemy pawn. Such a knight is very strong and should get a bonus. For example, if a White knight sits on d5 with a white pawn on c4 or e4 protecting it and Black has no pawn on c6 or e6 to chase it away, that knight could be given a significant bonus (say +30 or +40). The current engine doesn’t explicitly mention outposts; incorporating this would guide knight placement. Similarly, a bishop that sits on a long diagonal unopposed (especially if the opponent is missing the bishop of that color) could get a small bonus too.
Bishop Pair: The engine already acknowledges the bishop pair – it gives a bonus if a side has two bishops, scaled by how open the position is (fewer pawns = more bonus)
GitHub
. This is excellent, as two bishops work best in open positions. We should keep this feature and perhaps fine-tune the scaling. The current values (30 + 2 * openness) mean a bishop pair is worth +30 in a closed (pawn-heavy) position and up to +62 in a very open one (if openness = 16 with no pawns)
GitHub
. That seems reasonable.
Rook on Open File / Seventh Rank: These are already implemented: the engine checks for rooks on open files (no friendly pawns on that file) and gives a bonus, slightly smaller if the file is only semi-open (no friendly pawns but at least one enemy pawn)
GitHub
. It also gives rooks on the seventh rank a bonus
GitHub
, since a rook on the 7th (for White, rank 7; for Black, rank 2) can attack many of the opponent’s pieces and pawns from behind. These classical terms should be kept. We might also add a bonus for connected rooks (two rooks on the same rank or file with no pieces between them, or on adjacent open files), as they coordinate better, though this is a more minor factor.
“Bad” Minor Pieces: Penalize pieces that are particularly ineffective due to pawn structure. A well-known case is a “bad bishop” – a bishop whose own pawns block its mobility because many of them are on the same color squares as the bishop. You could count how many pawns a bishop has on its color complex. If a bishop is trapped behind a wall of its own pawns, a small penalty encourages the engine to improve that piece or trade it off. Likewise, a knight stuck on the rim (a1/h1/a8/h8 or similar) with limited moves might already be penalized by PST, but an additional slight penalty could be applied if a knight has less than, say, 2 legal moves available (indicating it’s stuck). The mobility score already addresses this to some extent (a knight with few moves will contribute less or even negative mobility if we considered enemy pieces it attacks that are defended), but a direct term can make it more explicit.
Tempo and Initiative: In static eval, it’s common to give a small bonus for having the move (to break symmetry). The engine does assign a tempo bonus of +10 for White to move (and -10 if Black to move)
GitHub
, which is a reasonable value. This encourages the side to move to make use of that move. Additionally, the eval calculates an initiative bonus based on mobility: essentially adding half of the mobility score difference to the side to move
GitHub
. The idea is to reward positions where you have more active pieces (which often means you can dictate play). These are good features to retain. We might consider also a development factor in the opening: e.g. give a slight bonus for each minor piece developed off the back rank, and a penalty if your pieces are still on their original squares by a certain stage of the game. This would require tracking game stage or move count, which complicates things, but it’s something classic engines did to avoid, say, leaving your bishops/knights unmoved for too long. Since we assume opening book handles main opening play, this may not be crucial. Nonetheless, a simple count of developed pieces (knights and bishops out) could feed into a small “development” bonus in the early game.
By incorporating these heuristics, the evaluation function becomes more aligned with human chess understanding and the techniques used in engines like Crafty and Stockfish (minus their neural components). Each addition – PST tuning, mobility, king safety, pawn structure, etc. – provides the engine with a clearer picture of who stands better and why. It’s important to balance the weights of these features; too large a penalty or bonus can skew play, so iterative testing and tuning (even using automated methods or self-play tournaments) is advised to find the right equilibrium. The result will be a stronger, more nuanced static evaluation that can guide the search to better moves.
3. Search Algorithm Enhancements
The search procedure is where the engine spends the most time, so employing sophisticated algorithms to prune the tree and explore the most promising lines is vital. The current engine implements a basic minimax search with alpha-beta pruning, and it already includes some advanced techniques (like move ordering, transposition tables, etc., as evidenced in the code). To further improve or fully utilize these capabilities – in line with what strong engines do – consider the following strategies:
Iterative Deepening (ID) with Aspiration Windows: Rather than searching to the full depth in one go, the engine should search incrementally deeper ply by ply, reusing information from previous depths. Iterative deepening is likely already in use (the engine’s find_best_move loop goes from depth 1 upward
GitHub
), and it’s beneficial because the best move at depth d often remains the best at depth d+1. By progressively deepening, you allow earlier, shallow searches to inform move ordering for later deeper searches. Typically, the engine keeps the principal variation (PV) from the previous depth and tries that move first at the next depth, greatly reducing branch factors. Additionally, using aspiration windows around the last best score can speed up alpha-beta convergence: instead of starting each search with alpha=-∞, beta=+∞, you start with a narrow window around the last score (e.g. ±50 or 100 centipawns)
GitHub
GitHub
. If the search fails low or high (score outside the window), you widen the window and research
GitHub
. This technique, visible in the engine’s _lazy_smp_worker and find_best_move logic
GitHub
GitHub
, avoids doing a full-width search every iteration and focuses the search where the score is likely to be. The combination of iterative deepening and aspiration search yields a significant efficiency gain, and it ensures that a best move is available even if the search is interrupted (useful for time-controlled searches).
Quiescence Search: Implement (or optimize) a quiescence search at the leaves of the tree to combat the horizon effect. The idea is to extend the search for “noisy” positions – typically where there are still captures or checks available – until a quiet position is reached (no major material changes about to happen). The engine does have a _quiescence function
GitHub
GitHub
 that continues searching captures and check-giving moves. This is essential because a static evaluation at a leaf where, say, a queen can be captured next move is highly misleading. The quiescence search should evaluate all forcing moves (captures, promotions, possibly checks) until the position stabilizes. The current implementation already filters to moves that are captures or give check
GitHub
, and even uses delta pruning and SEE (Static Exchange Evaluation) pruning to skip obviously bad captures
GitHub
. Those are good optimizations: for instance, if a capture’s value plus a margin is not enough to raise the score above alpha, it’s pruned
GitHub
, and if SEE indicates the move loses material, it’s pruned
GitHub
. Make sure all these mechanisms are correctly implemented so quiescence search doesn’t explode in tactical positions. A well-tuned quiescence search will greatly improve the engine’s tactical stability, evaluating only quiet positions with the static eval.
Transposition Tables (TT): Utilizing a transposition table is crucial for avoiding redundant calculations. The engine should maintain a large hash table (indexed by a Zobrist hash of the position) to store search results from explored positions
GitHub
. This appears to be implemented: the code uses a _TT_ARRAY and stores entries with depth, value, flag (exact/alpha/beta), and best move
GitHub
GitHub
. The TT allows the search to retrieve a previously computed value for a position and cut off the search if the stored value is good enough to prove the move is not beneficial or is definitely beneficial. For example, if a position was searched to depth 5 earlier and now we reach it again at depth 4, we can safely reuse the stored value (since it’s from an equal or deeper search)
GitHub
. The engine’s code respects this by returning the TT value when an entry’s stored depth is >= current depth and the flags indicate it’s an exact score or a bound that prunes the range
GitHub
. Ensure that whenever a search finishes at a node, the result is stored in the TT with the appropriate flag: flag = exact if the move was fully searched (no cutoff)
GitHub
, lower bound if a beta-cutoff occurred
GitHub
, or upper bound if the node failed low. Also store the best move found, as the engine does, to aid move ordering on future visits
GitHub
GitHub
. You might increase the TT size if memory permits, to improve hit rates (the default shown is 1<<20 entries ≈ 1 million positions
GitHub
, which is fine for a Python engine). Proper use of the TT can yield large speedups, especially in positions with transpositions or repeated subtrees, by cutting off search or using the stored best move to get immediate alpha-beta cutoffs.
Move Ordering Heuristics: Good move ordering is what makes alpha-beta efficient (in the best case, reducing complexity from O(b^d) to O(b^(d/2))). The engine already employs several move-ordering heuristics, which we should maintain and possibly refine:
Transposition Table Move: Always try the TT’s stored best move first if available
GitHub
GitHub
. Often this is the principal variation from a previous iteration or another branch, and it has a high chance of causing a beta-cutoff again. The code inserts a large bonus for the TT move in move ordering (e.g. +1,000,000 to the score)
GitHub
, ensuring it gets sorted to the front. This should remain as a top priority ordering rule.
Captures and Winning Moves First: The engine sorts captures using SEE (Static Exchange Evaluation) to prioritize moves that gain material
GitHub
. Typically, ordering by MVV-LVA (most valuable victim, least valuable attacker) is a simple rule: capture the most valuable piece with the least valuable attacker first. The engine’s approach is even better – using SEE and adding a base +100,000 plus the SEE value for captures
GitHub
 means moves that likely win material or at least are trades come first in the ordering. Ensure that this ordering remains, so that obvious good captures are tried before quiet moves. The engine also gives a bonus for moves that deliver check
GitHub
, and even higher if it’s a checking move that results in immediate mate
GitHub
. This focuses the search on forcing moves that could end the game.
Killer Moves: Implement the killer heuristic – if a non-capturing move caused a beta-cutoff at a given depth, mark it as a “killer” for that depth. On other branches at the same depth, try the killer moves early, because a move that caused a cutoff once might do so again in a similar position. The engine maintains two killer moves per depth (the typical approach) and gives them large bonuses in ordering (e.g. +900,000 and +800,000)
GitHub
. This should definitely be kept. Each time a move (that is not a capture) causes a beta cutoff, update the killer list for that depth
GitHub
, shifting the older killer down and storing the new one on top
GitHub
. With this, the search will try those killer moves early in sibling nodes, often getting quick cutoffs.
History Heuristic: Incorporate a history table that records how often moves lead to cutoffs or good outcomes. The current engine has a _HISTORY dictionary and even a refined “butterfly” mechanism to scale it
GitHub
. Each time a move causes a beta cutoff, the engine adds depth^2 to a history counter for that move
GitHub
. Moves that were frequently good will accumulate a high score. In move ordering, a move’s history score can be used to sort non-captures: the engine divides the history score by a “butterfly” count (the number of times that move was tried) to get a heuristic value
GitHub
, and adds that to the ordering score. This way, moves that are historically successful are considered earlier in the search. Continue to use and refine this heuristic. Over many searches, this guides the engine to explore promising moves first even if they haven’t yet caused a cutoff in the current branch. It’s a long-term learning mechanism within a single search instance (not across games).
Countermove Heuristic: This is a more advanced ordering idea implemented in top engines, and the code hints at it with a _COUNTER table
GitHub
. The concept: whenever a move fails to produce a cutoff (i.e. was the previous move and didn’t cause a beta-cutoff), record the best response to that move (the move that refuted it) as a “countermove.” Next time that same previous move is seen in a sibling branch, try the recorded counter move first. The engine updates _COUNTER[prev_move] = current_move on a cutoff
GitHub
, meaning “if the opponent plays prev_move, our engine should consider current_move as a strong response.” And in ordering, it gives a bonus if the previous move’s recorded counter matches the current move being ordered
GitHub
. This heuristic is quite powerful in narrowing down refutations quickly, and the engine’s inclusion of it is forward-thinking. Keep this mechanism and verify that it’s being used in the move ordering (which it is, adding +700,000 when a move matches the counter for the previous opponent move
GitHub
).
Late Move Reductions (LMR): This technique prunes the search tree by reducing the depth of “late” moves. The idea: after examining a few likely good moves at a node, assume that the later moves (move number 4, 5, 6, … in the ordering) are probably not as good, so search them with a shallower depth. If they turn out to be interesting (i.e., they return a score above alpha), then re-search them at full depth. The engine implements LMR – for moves after the first couple, it computes a reduction based on depth and move index
GitHub
GitHub
. For example, in the code, if depth >= 3 and this is the 4th move or later (i >= 3) and it’s not a capture or check, it calculates a reduction amount (using a base and logarithmic formula)
GitHub
. Then it searches the move with depth - 1 - reduction (slightly shallower) on a narrow alpha-beta window
GitHub
. If the move’s score comes back greater than alpha, meaning “even with reduced depth it did better than expected,” the code triggers a re-search at full depth to verify
GitHub
GitHub
. This way, no good move is lost – any move that might raise alpha gets a second chance at full depth – but a lot of bad moves are cut short. LMR can hugely reduce nodes examined (Stockfish relies on it heavily). Ensure the implementation is sound: typically, you don’t reduce the first one or two moves (so the best moves always get full depth), and you never reduce if you’re in a check or near mate. The engine already avoids reductions for captures, checks, or moves that move closer to the enemy king (labeled converges)
GitHub
, since those are tactical moves that shouldn’t be prematurely reduced. The parameters LMR_BASE, LMR_DIV in the code control the reduction severity
GitHub
; those might be tuned via testing or SPSA. Overall, continuing to refine LMR will yield a faster search with minimal loss in strength.
Other Alpha-Beta Enhancements: In addition to the above, the engine uses a few more advanced pruning and extension techniques which are worth maintaining:
Null Move Pruning: This is a widely used heuristic where you allow the side to move to skip their move (a “null move”) to see if the position is so good that even without moving, the eval is above beta. If a null move yields a beta-cutoff (after a reduced-depth search), it suggests a strong positional advantage, and the engine prunes the branch (because the opponent must address the threat). The engine’s code includes null move logic (it does a null move search with a reduction R when depth ≥ 3)
GitHub
. Make sure this stays in use, as it can significantly prune defensive moves when the side to move is overwhelmingly ahead. Be cautious with null move in zugzwang-prone positions (endgames where passing loses advantage) – usually engines disable null move when in check or in low material endgames. The current implementation skips null move when in check
GitHub
, which is correct.
Futility Pruning and Razoring: These are shallow pruning techniques. The engine already does something akin to razoring at depth <= 2: it compares a shallow static eval to alpha with a margin
GitHub
. If the position is way too bad (even best-case improvement won’t reach alpha), it goes straight to quiescence (prune deeper search)
GitHub
. Also, if the static eval is well above beta, it may return that (though the engine only does that if eval_static - margin >= beta, which is a form of shallow beta cutoff)
GitHub
. These tricks cut off obviously hopeless branches early. Keep these in place and consider also futility pruning for late moves at depth 1: e.g., if a quiet move at depth 1 can’t possibly raise the score to alpha (based on material alone), you might skip it. However, be careful to not prune tactical moves – the current SEE-based skip for losing captures is a safe example
GitHub
GitHub
. Every pruning must be tested to ensure it doesn’t cut potential winning lines.
Parallel Search and Others: Although not asked explicitly, it’s worth noting that the engine’s UCI mode supports multi-threading (using a Lazy SMP approach). In a multi-thread scenario, each thread runs an iterative deepening search with shared transposition table
GitHub
GitHub
. This is a modern technique that Stockfish uses to great effect. Ensuring the transposition table is shared and synchronized (the code uses a multiprocessing Array and Lock for this
GitHub
) will help scalability. Since the question focuses on algorithmic improvements, we won’t dive deeply into parallelism, but it’s good to align any search enhancements with multi-threading in mind (e.g. thread-safe TT updates, splitting root moves across threads, etc., which the engine is already doing with _search_move_thread for root splits
GitHub
).
In summary, the search can be strengthened by fully utilizing alpha-beta enhancements: iterative deepening, quiescence, transposition tables, and heuristics like move ordering, killers, history, and late move reductions. These techniques drastically reduce the branching factor and direct the engine’s efforts to the most relevant moves. Engines like Stockfish and Crafty owe much of their strength not just to evaluation, but to how efficiently they search – using the same ideas listed above. By implementing and fine-tuning these algorithms (as the engine is already on track to do, according to its code), the engine will search deeper in the same amount of time and find stronger moves. Each improvement – whether it’s pruning a fruitless branch via null move, ordering moves so a cutoff comes quicker, or extending the search in a critical tactical sequence via quiescence – contributes to a more robust and competitive chess engine. Overall, focusing on efficient move generation, a rich and tuned evaluation, and a highly optimized alpha-beta search will yield an engine that embodies many of the strengths of classical engines like Stockfish (pre-neural network era) or Crafty. All these recommendations work together: faster move generation feeds the search, a smarter evaluation guides move ordering (through score influences on pruning), and a powerful search makes the most of the CPU time. By iteratively refining these areas and testing, one can achieve significant ELO gains for the engine.
GitHub
GitHub
GitHub
GitHub
